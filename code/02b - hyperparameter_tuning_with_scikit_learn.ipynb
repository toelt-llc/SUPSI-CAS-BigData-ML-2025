{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with scikit-learn\n",
    "\n",
    "This notebooks contains a few examples on how hyperparameter tuning works with scikit-learn.\n",
    "\n",
    "Author: Umberto Michelucci (umberto.michelucci@toelt.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we always need to define what hyperparameters we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define what kind of model we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will generate some *fake* data to use for our tuning.\n",
    "\n",
    "The `make_classification` function is a utility provided by scikit-learn. This function is specifically used for generating a random n-class classification problem. It is an essential tool for creating synthetic datasets, which are particularly useful for testing and benchmarking machine learning algorithms.\n",
    "\n",
    "Here are the key aspects of the `make_classification` function:\n",
    "\n",
    "1. **Purpose**: The primary purpose of `make_classification` is to generate a random, multiclass classification problem. This helps in creating controlled datasets to test classification algorithms and to understand their behavior under various scenarios.\n",
    "\n",
    "2. **Customizability**: It offers a high degree of customizability. Users can specify several parameters such as the number of samples, the number of features (total, informative, redundant, and repeated), the number of classes, and the level of class separation. This flexibility allows for the creation of datasets with specific characteristics, tailored to particular testing needs.\n",
    "\n",
    "3. **Output**: The function outputs a tuple containing two arrays: the first array is the generated features (X), and the second array is the class labels for each feature vector (y).\n",
    "\n",
    "4. **Parameters**:\n",
    "   - `n_samples`: The number of samples to generate.\n",
    "   - `n_features`: The total number of features. These include informative, redundant, and noise features.\n",
    "   - `n_informative`: The number of informative features, i.e., features actually used to build the classification model.\n",
    "   - `n_redundant`: The number of redundant features, which are linear combinations of the informative features.\n",
    "   - `n_classes`: The number of classes (or labels) in the dataset.\n",
    "   - `weights`: The proportions of samples assigned to each class.\n",
    "   - `class_sep`: A parameter that controls the degree of class separation.\n",
    "   - And many more parameters to control various aspects of the dataset.\n",
    "\n",
    "\n",
    "5. **Applications**: It is widely used in machine learning for algorithm development, testing, and comparison. Researchers and practitioners often use it to simulate various data distributions and imbalances to evaluate the performance of classification algorithms under controlled conditions.\n",
    "\n",
    "6. **Ease of Use**: Like many scikit-learn functions, `make_classification` is user-friendly, making it accessible for both beginners and experienced practitioners in the field of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search - Halving Grid Search\n",
    "\n",
    "`HalvingGridSearchCV` is a function provided by scikit-learn, a widely used Python library for machine learning. It is part of the model selection module and offers an efficient approach to hyperparameter tuning. This function is designed to find the best parameters for a given model through a process known as \"successive halving,\" which is a more resource-efficient version of the traditional grid search.\n",
    "\n",
    "Key characteristics and functionalities of `HalvingGridSearchCV` include:\n",
    "\n",
    "1. **Purpose**: The primary objective of `HalvingGridSearchCV` is to identify the best hyperparameters for a given model. It does this by systematically working through multiple combinations of parameter values, evaluating each combination's performance.\n",
    "\n",
    "2. **Successive Halving Algorithm**: Unlike the traditional grid search that evaluates all combinations of parameter values, `HalvingGridSearchCV` employs the successive halving algorithm. This algorithm initially evaluates a large number of hyperparameter combinations with a small number of resources and then successively halves the number of combinations, allocating more resources to the more promising ones.\n",
    "\n",
    "3. **Resource Efficiency**: This approach significantly reduces computation time and resource usage, making it more efficient, especially when dealing with large datasets or complex models.\n",
    "\n",
    "4. **Parameters and Attributes**:\n",
    "   - It inherits parameters similar to `GridSearchCV`, like `estimator` for the model, `param_grid` for the grid of parameters, `scoring` for the scoring method, and `cv` for cross-validation strategy.\n",
    "   - `factor`: Determines the rate at which the number of configurations is reduced at each iteration.\n",
    "   - `resource`: The resource that is increased at each iteration (e.g., the number of iterations for an iterative algorithm).\n",
    "   - `min_resources`: The minimum amount of resource allocated to each configuration during the first iteration.\n",
    "\n",
    "5. **Cross-Validation**: It uses cross-validation to evaluate the performance of each set of parameters, ensuring a thorough and unbiased assessment.\n",
    "\n",
    "6. **Applications**: `HalvingGridSearchCV` is particularly useful in scenarios where the parameter space is large, and a traditional grid search would be too time-consuming or computationally expensive.\n",
    "\n",
    "7. **Results**: It provides detailed results that include the best parameters found, the score of the best parameters, and the complete results of the search process.\n",
    "\n",
    "\n",
    "Finally we can do the actual search. By default, the resource is defined in terms of number of samples. That is, each iteration will use an increasing amount of samples to train on. You can however manually specify a parameter to use as the resource with the resource parameter. Here is an example where the resource is defined in terms of the number of estimators of a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                    factor=2, resource='n_estimators',\n",
    "                    max_resources=30).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can get the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the number of resources that is used at each iteration depends on the ```min_resources``` parameter. If you have a lot of resources available but start with a low number of resources, some of them might be wasted (i.e. not used). Let us try a different example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid= {'kernel': ('linear', 'rbf'),\n",
    "              'C': [1, 10, 100]}\n",
    "base_estimator = SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                          factor=2, min_resources=20).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 40, 80]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.n_resources_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search process will only use 80 resources at most, while our maximum amount of available resources is ```n_samples=1000```. Here, we have ```min_resources = r_0 = 20```. For ```HalvingGridSearchCV```, by default, the min_resources parameter is set to ```exhaust```. This means that min_resources is automatically set such that the last iteration can use as many resources as possible, within the max_resources limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more possibilities, and looking at the official documentation is always a good idea to explore all possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cv_results_ attribute contains useful information for analyzing the results of a search. It can be converted to a pandas dataframe with ```df = pd.DataFrame(est.cv_results_)```.\n",
    "\n",
    "The `cv_results_` attribute in scikit-learn, particularly in model selection tools like `GridSearchCV` and `HalvingGridSearchCV`, is a dictionary that holds a lot of detailed information about the results of the cross-validation process. It is generated after the fitting process (`fit` method) of the model selection tool is completed.\n",
    "\n",
    "Key aspects of the `cv_results_` attribute include:\n",
    "\n",
    "1. **Detailed Results**: It contains detailed outcomes for each parameter combination that was evaluated during the cross-validation. This information is invaluable for analyzing and understanding the performance of different hyperparameter configurations.\n",
    "\n",
    "2. **Structure**: The dictionary includes various keys, each corresponding to different aspects of the results. Common keys include:\n",
    "   - `mean_test_score`: The mean score of the test set on different folds.\n",
    "   - `std_test_score`: The standard deviation of the test set score over different folds.\n",
    "   - `mean_train_score` and `std_train_score`: Similar metrics for the training set (if `return_train_score` is set to True).\n",
    "   - `params`: A list of parameter settings corresponding to each result.\n",
    "   - `rank_test_score`: The rank of each parameter setting based on the test score.\n",
    "   - `split_i_test_score` (where i is the fold number): The test score for each split.\n",
    "   - `time_fit`: The time taken to fit the model on the train set for each parameter setting.\n",
    "   - `time_score`: The time taken to score the model on the test set for each parameter setting.\n",
    "\n",
    "3. **Analysis and Visualization**: This attribute is often used for analyzing the results in detail. You can sort and filter the results to identify the best performing parameter combinations. It is also commonly used for visualizing the results, such as plotting the scores against different hyperparameters to see how they affect the model performance.\n",
    "\n",
    "4. **Decision Making**: The information in `cv_results_` is critical for making informed decisions about which hyperparameters are the most effective for a given model and dataset.\n",
    "\n",
    "5. **Post-Processing**: Researchers and practitioners can export this data into data frames (e.g., using Pandas) for easier manipulation and more advanced analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>n_resources</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.339116</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.339116</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.101550</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iter  n_resources  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "0      0           20       0.000358      0.000119         0.000158   \n",
       "1      0           20       0.000260      0.000005         0.000140   \n",
       "2      0           20       0.000361      0.000130         0.000155   \n",
       "3      0           20       0.000521      0.000169         0.000246   \n",
       "4      0           20       0.000355      0.000063         0.000205   \n",
       "5      0           20       0.000278      0.000014         0.000145   \n",
       "6      1           40       0.000345      0.000024         0.000176   \n",
       "7      1           40       0.000604      0.000265         0.000232   \n",
       "8      1           40       0.000308      0.000018         0.000146   \n",
       "9      2           80       0.000452      0.000044         0.000262   \n",
       "10     2           80       0.000417      0.000054         0.000164   \n",
       "\n",
       "    std_score_time param_C param_kernel                          params  \\\n",
       "0         0.000025       1       linear    {'C': 1, 'kernel': 'linear'}   \n",
       "1         0.000005       1          rbf       {'C': 1, 'kernel': 'rbf'}   \n",
       "2         0.000023      10       linear   {'C': 10, 'kernel': 'linear'}   \n",
       "3         0.000058      10          rbf      {'C': 10, 'kernel': 'rbf'}   \n",
       "4         0.000092     100       linear  {'C': 100, 'kernel': 'linear'}   \n",
       "5         0.000005     100          rbf     {'C': 100, 'kernel': 'rbf'}   \n",
       "6         0.000019       1       linear    {'C': 1, 'kernel': 'linear'}   \n",
       "7         0.000092      10       linear   {'C': 10, 'kernel': 'linear'}   \n",
       "8         0.000005     100       linear  {'C': 100, 'kernel': 'linear'}   \n",
       "9         0.000108      10       linear   {'C': 10, 'kernel': 'linear'}   \n",
       "10        0.000011     100       linear  {'C': 100, 'kernel': 'linear'}   \n",
       "\n",
       "    split0_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0              0.7500  ...           0.6500        0.374166                6   \n",
       "1              0.7500  ...           0.6000        0.300000                9   \n",
       "2              0.7500  ...           0.6500        0.374166                6   \n",
       "3              0.7500  ...           0.6000        0.339116                9   \n",
       "4              0.7500  ...           0.6500        0.374166                6   \n",
       "5              0.7500  ...           0.6000        0.339116                9   \n",
       "6              0.8750  ...           0.8250        0.100000                2   \n",
       "7              0.8750  ...           0.8250        0.100000                2   \n",
       "8              0.8750  ...           0.8250        0.100000                2   \n",
       "9              1.0000  ...           0.8375        0.101550                1   \n",
       "10             0.9375  ...           0.8250        0.082916                2   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0                  1.0                 1.0                 1.0   \n",
       "1                  1.0                 1.0                 1.0   \n",
       "2                  1.0                 1.0                 1.0   \n",
       "3                  1.0                 1.0                 1.0   \n",
       "4                  1.0                 1.0                 1.0   \n",
       "5                  1.0                 1.0                 1.0   \n",
       "6                  1.0                 1.0                 1.0   \n",
       "7                  1.0                 1.0                 1.0   \n",
       "8                  1.0                 1.0                 1.0   \n",
       "9                  1.0                 1.0                 1.0   \n",
       "10                 1.0                 1.0                 1.0   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0                  1.0                 1.0               1.0              0.0  \n",
       "1                  1.0                 1.0               1.0              0.0  \n",
       "2                  1.0                 1.0               1.0              0.0  \n",
       "3                  1.0                 1.0               1.0              0.0  \n",
       "4                  1.0                 1.0               1.0              0.0  \n",
       "5                  1.0                 1.0               1.0              0.0  \n",
       "6                  1.0                 1.0               1.0              0.0  \n",
       "7                  1.0                 1.0               1.0              0.0  \n",
       "8                  1.0                 1.0               1.0              0.0  \n",
       "9                  1.0                 1.0               1.0              0.0  \n",
       "10                 1.0                 1.0               1.0              0.0  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sh.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to a given parameter combination (a candidate) and a given iteration. The iteration is given by the ```iter column```. The ```n_resources``` column tells you how many resources were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are interested in knowing how hyperband works, you can refer to L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, A. Talwalkar, Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization, in Machine Learning Research 18, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = GridSearchCV(estimator=base_estimator, param_grid=param_grid, cv=5).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038135</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344359</td>\n",
       "      <td>0.101205</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009231</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.010620      0.002191         0.000989        0.000178       1   \n",
       "1       0.008536      0.000126         0.003256        0.000122       1   \n",
       "2       0.038135      0.004567         0.000855        0.000046      10   \n",
       "3       0.008928      0.000406         0.002931        0.000070      10   \n",
       "4       0.344359      0.101205         0.000902        0.000051     100   \n",
       "5       0.009231      0.000503         0.002938        0.000138     100   \n",
       "\n",
       "  param_kernel                          params  split0_test_score  \\\n",
       "0       linear    {'C': 1, 'kernel': 'linear'}              0.930   \n",
       "1          rbf       {'C': 1, 'kernel': 'rbf'}              0.910   \n",
       "2       linear   {'C': 10, 'kernel': 'linear'}              0.930   \n",
       "3          rbf      {'C': 10, 'kernel': 'rbf'}              0.905   \n",
       "4       linear  {'C': 100, 'kernel': 'linear'}              0.930   \n",
       "5          rbf     {'C': 100, 'kernel': 'rbf'}              0.895   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.965              0.930              0.885              0.940   \n",
       "1              0.950              0.935              0.890              0.925   \n",
       "2              0.965              0.935              0.875              0.940   \n",
       "3              0.910              0.915              0.860              0.895   \n",
       "4              0.965              0.935              0.875              0.940   \n",
       "5              0.920              0.900              0.860              0.875   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.930        0.025884                1  \n",
       "1            0.922        0.020640                4  \n",
       "2            0.929        0.029563                2  \n",
       "3            0.897        0.019647                5  \n",
       "4            0.929        0.029563                2  \n",
       "5            0.890        0.020736                6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sh.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A - the Halving Grid Search Algorithm\n",
    "\n",
    "The Halving Grid Search algorithm, implemented as `HalvingGridSearchCV` in scikit-learn, is an efficient method for hyperparameter tuning. It is a part of the broader family of algorithms known as Successive Halving algorithms. The key idea behind this approach is to iteratively refine the search for the best hyperparameters by allocating resources more efficiently. Here's a detailed description of how it works:\n",
    "\n",
    "1. **Initial Setup**:\n",
    "   - The algorithm begins with a predefined grid of hyperparameter values. Each combination of hyperparameters in this grid is considered a candidate.\n",
    "   - It also requires the definition of a resource, which is usually a measure of how much training a model receives (like the number of iterations, depth of a tree, etc.).\n",
    "\n",
    "2. **Initial Evaluation**:\n",
    "   - In the first iteration, all hyperparameter candidates are trained with a small, equal amount of the resource. This initial resource level is usually set by the user.\n",
    "   - Once trained, each candidate is evaluated using a specified metric (like accuracy, F1-score, etc.).\n",
    "\n",
    "3. **Selection and Halving**:\n",
    "   - After evaluating all candidates, a subset of the best-performing candidates is selected. Typically, this selection cuts the number of candidates in half, hence the term \"halving.\"\n",
    "   - The key aspect of this step is that only a fraction of candidates (the most promising ones) continue to the next round.\n",
    "\n",
    "4. **Resource Doubling**:\n",
    "   - For the next iteration, the amount of resource allocated to each remaining candidate is doubled (or increased by a factor specified by the user).\n",
    "   - These candidates are then re-trained with this increased resource and re-evaluated.\n",
    "\n",
    "5. **Iterative Process**:\n",
    "   - Steps 3 and 4 are repeated. In each iteration, the number of candidates is halved, and the resources allocated to each remaining candidate are increased (typically doubled).\n",
    "   - This process continues until a stopping criterion is met, which could be a maximum resource limit or a minimum number of candidates remaining.\n",
    "\n",
    "6. **Final Selection**:\n",
    "   - The final set of hyperparameters is chosen based on the best performance observed in the last iteration of the process.\n",
    "\n",
    "### Advantages of the Halving Grid Search Algorithm:\n",
    "\n",
    "- **Efficiency**: By allocating resources more effectively and focusing on promising candidates, it significantly reduces the computational cost compared to traditional grid search, which is beneficial for large hyperparameter spaces.\n",
    "- **Flexibility**: It works with any type of model and is applicable to a wide range of hyperparameter optimization problems.\n",
    "- **Scalability**: The algorithm scales well with the size of the dataset and the complexity of the model.\n",
    "\n",
    "### Key Considerations:\n",
    "\n",
    "- **Resource Definition**: The choice of resource and how it impacts model training is crucial. The resource could be the number of iterations, number of trees (in ensemble methods), or any other measure that directly affects the training extent of the model.\n",
    "- **Initial Resource Allocation**: The amount of resource allocated in the initial step can impact the algorithm's effectiveness. Too little resource might not be sufficient to reveal the potential of certain candidates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
